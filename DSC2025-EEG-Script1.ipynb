{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca4de35-9504-4d00-8121-abad402d73fd",
   "metadata": {},
   "source": [
    "## Script 1: First steps in visualizing and processing the EEG data\n",
    "\n",
    "In this script you will be introduced to the basics of visualizing and manipulating EEG data using\n",
    "MNE-Python package.\n",
    "\n",
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you are working in Binder, you will need to upload these two files into the data folder:\n",
    "- sub-001_eeg_sub-001_task-think1_eeg_short.set\n",
    "- sub-001_eeg_sub-001_task-think1_eeg_short.fdt\n",
    "It might take a few minutes to upload them so be patient.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426665bd-9362-43f3-838e-a90a20da076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the necessary packages, read in the raw EEG data (in bdf format) and visualize the raw data.\n",
    "## Note when we load in the data using mne.io.read_raw_bdf() this creates a raw object. \n",
    "## In the following code, our raw object is rawIn.\n",
    "%matplotlib widget\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "fname = 'sub-001_eeg_sub-001_task-think1_eeg_short.set'\n",
    "filepath = 'data'\n",
    "fullpath = os.path.join(filepath, fname)\n",
    "rawIn = mne.io.read_raw_eeglab(fullpath, preload=True)\n",
    "\n",
    "rawIn.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567413f-35d7-4c09-b3e6-15687a2a4aef",
   "metadata": {},
   "source": [
    "### A note concerning the external EEG electrodes or channels of the data that you have just imported.\n",
    "\n",
    "EXG1 and EXG2: HEOG (horizontal electrooculogram)\n",
    "EXG3 and EXG4: VEOG (vertical electrooculogram or eye-blinks)\n",
    "EXG7: ECG (electro-cardiogram)\n",
    "EXG5: Mastoid 1\n",
    "EXG6: Mastoid 2\n",
    "EXG8: Fp1 electrode\n",
    "\n",
    "Now we will set the auxiliary channels to type MISC, EXG1-6 to eog and the stimulus channel to 'stim'\n",
    "By doing this each data type is scaled appropriately when visualized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8bce8-be33-456e-836f-427568ab4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'EXG1': 'eog', 'EXG2': 'eog', 'EXG3': 'eog', 'EXG4': 'eog', 'EXG5': 'eog', 'EXG6': 'eog', 'EXG7': 'eog',\n",
    "           'EXG8': 'eog',\n",
    "           'GSR1': 'misc', 'GSR2': 'misc', 'Erg1': 'stim', 'Erg2': 'stim', 'Resp': 'resp', 'Plet': 'misc',\n",
    "           'Temp': 'misc'}\n",
    "print(my_dict)\n",
    "rawIn.set_channel_types(my_dict)  # Apply the channel type to our raw object.\n",
    "mne.viz.plot_raw(rawIn, duration=5.0, scalings=\"auto\", remove_dc=True)  # Plot again the Channels X Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dfc7eb-006e-4fcd-99a2-637076868dde",
   "metadata": {},
   "source": [
    "### Getting some basic dataset information from the .info() object.\n",
    "\n",
    "Now we will extract some basic information about the dataset by looking at the rawIn.info attribute,\n",
    "which contains an 'info' object. This info object is a python dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2f97e-a1f0-48cb-80ab-c89e9d814e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawIn.info['sfreq']         # To access the sampling frequency information \n",
    "print(rawIn.info)           # Visualising all dataset information\n",
    "print(rawIn.info['sfreq'])  # Display the sampling frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44eca04-8457-4571-8e6d-a7efa3d2b8c3",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Try displaying the following information in the console:\n",
    "- channel names\n",
    "- the number and the type of channels\n",
    "Put the code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02812b39-6b83-44b5-80f9-d34bc1cc230f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45e18f-fded-441b-bcd3-4044c0561251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass the information in the info object to a new variable.\n",
    "\n",
    "sfreq = rawIn.info['sfreq']      # We are assigning our sampling frequency information to the variable sfreq\n",
    "print('The sampling frequency of the current dataset is {} Hz.'.format(sfreq))  # using .format() method to print variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386c71f-3925-4032-b7d3-5f99e308da6e",
   "metadata": {},
   "source": [
    "## Now we extract the actual microVolt EEG data from the rawIn object.\n",
    "\n",
    "We use the .get_data() method. \n",
    "This should give us a matrix with the form: number of electrodes X number of time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ac65c-7a2e-4b4c-aad3-f64e13dad5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataIn = rawIn.get_data()\n",
    "dataDims = dataIn.shape      # To get the dimensions of our data. \n",
    "print(f'The number of channels in the current raw dataset is {dataDims[0]}.\\n')\n",
    "print(f'The number of time samples in the current raw dataset is {dataDims[1]}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea4caa-eb0a-42c0-be27-fccd136efd2f",
   "metadata": {},
   "source": [
    "Now that you know the sampling frequency (Hz) and the number of data samples,\n",
    "try to do the following:\n",
    "- calculate the duration of the data in seconds.\n",
    "- create the time vector\n",
    "Remember that the sampling frequency tells you how many time samples there are in 1 second of data. \n",
    "The sampling frequency can be used to calculate the time step from one sample to the next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c5741-5743-4da1-9c83-fa0b29dc2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamps = dataDims[1]\n",
    "tstep = 1 / sfreq                         # This is the time step. \n",
    "T = [(n * tstep) for n in range(nSamps)]  # We create the time vector. \n",
    "\n",
    "print(f'The length of the time vector is {len(T)}')\n",
    "print(f'The duration of the time vector is {T[-1]} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a1bdc-fd81-444f-811d-62cb4166c83a",
   "metadata": {},
   "source": [
    "### Plot a single electrode\n",
    "\n",
    "1. Plot a single electrode over the entire duration of the data. \n",
    "We can use the time vector (T) that we constructed.\n",
    "\n",
    "2. Plot a single electrode over a defined time interval. \n",
    "3. Plot several electrodes against each other. \n",
    "\n",
    "In the following example we will plot the EEG signal of the Cz electrode over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cd66e-cb7e-4eec-9b76-1f3b355a1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "channelNames = rawIn.info['ch_names']\n",
    "chan2plot = 'Cz'\n",
    "chanIndx = channelNames.index(chan2plot)\n",
    "print(f'The index of channel {chan2plot} is {chanIndx}.')\n",
    "\n",
    "plt.plot(T, dataIn[chanIndx, :])\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecefac1-213c-4626-aa4b-2c966d1a1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single electrode over a pre-defined time interval (60 to 70seconds after the start of the data)\n",
    "\n",
    "timeLims = np.array([60, 70])\n",
    "lim1, lim2 = (timeLims * sfreq).astype(int)   # Express the time limits of the interval as indices.\n",
    "\n",
    "# Plot\n",
    "plt.plot(T[lim1:lim2], dataIn[chanIndx, lim1:lim2])\n",
    "plt.xlabel('time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1231c-16d1-4991-9af1-09fdf5f6a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two electrodes against each other\n",
    "\n",
    "chans2plot = ['Cz', 'Pz']\n",
    "channelIndices = [i for i, chan in enumerate(channelNames) if chan in chans2plot]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for idx in channelIndices:\n",
    "    ax.plot(T[lim1:lim2], dataIn[idx, lim1:lim2])\n",
    "ax.set_xlabel('time (seconds)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29080095-c891-47ee-814a-8bff831a18dd",
   "metadata": {},
   "source": [
    "You can notice that the two electrode signals do not at all overlap. \n",
    "Why could this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68680e-355e-4cf8-8216-0feb6838034d",
   "metadata": {},
   "source": [
    "### The DC Component or the 0Hertz Component\n",
    "\n",
    "The DC Offset:\n",
    "You notice that none of the electrodes appear to be visible...this is due to what we call the \"**DC Offset**\".\n",
    "The acquisition system works on battery, so DC, and it captures ALL the frequencies including the OHz.\n",
    "The OHz is the offset from zero mean. \n",
    "So we need to remove this offset; after which our signals will have a zero mean.\n",
    "\n",
    "There are different ways of removing the DC Offset:\n",
    "\n",
    "We will start by trying to remove the DC offset, by subtracting the mean activity from the activity of one channel.\n",
    "Then we will plot the result.\n",
    "So...\n",
    "- Let's calculate the mean of a few channels.\n",
    "- What do you notice about the means? How do we know that there is a DC offset?\n",
    "\n",
    "Note also the use of the *copy()** method. We use this to make a copy of the original **RawIn** object.\n",
    "When we apply a method such as, *.pick_channels*, to a raw object, we change that object. Therefore, the copy() method is very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23145675-8eab-4278-9089-0b4560ca4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInbis = rawIn.copy()  # creating a copy of the raw object.\n",
    "rawInbis.pick_channels(['Fz', 'Cz', 'Pz'])\n",
    "dataInbis = rawInbis.get_data()  # Get the data of the selected channels.\n",
    "dataMean = np.mean(dataInbis, 1)\n",
    "dataMean = dataMean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958fdcd-76d3-41bf-af6b-d73185dd5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the channels before and after subtracting the mean.\n",
    "ax1 = plt.subplot(231)\n",
    "ax1.margins(0.5)\n",
    "ax1.plot(T, dataIn[0,])\n",
    "\n",
    "ax2 = plt.subplot(232)\n",
    "ax2.margins(0.5)\n",
    "ax2.plot(T, dataIn[1,])\n",
    "\n",
    "ax3 = plt.subplot(233)\n",
    "ax3.margins(0.5)\n",
    "ax3.plot(T, dataIn[2,])\n",
    "\n",
    "ax4 = plt.subplot(234)\n",
    "ax4.margins(0.5)\n",
    "ax4.plot(T, chan_demean1)\n",
    "\n",
    "ax5 = plt.subplot(235)\n",
    "ax5.margins(0.5)\n",
    "ax5.plot(T, chan_demean2)\n",
    "\n",
    "ax6 = plt.subplot(236)\n",
    "ax6.margins(0.5)\n",
    "ax6.plot(T, chan_demean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f412f-412f-4d87-b7ae-c5da86005374",
   "metadata": {},
   "source": [
    "### Remove the DC component by high-pass filtering.\n",
    "\n",
    "The generally applied approach in EEG data processing is to apply a high-pass filter to the EEG data.\n",
    "Remember we want to remove the 0Hz, DC component.\n",
    "Here we apply a high-pass filter with a cutoff at 0.1Hz. This means that we remove all frequencies below 0.1Hz and retain all \n",
    "frequencies above 0.1Hz. \n",
    "We will use the .filter() method in MNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f07e86-bc63-419b-8e09-ffa7f8ccce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInFilt = rawIn.copy().filter(0.1, None,\n",
    "                                fir_design='firwin')  # Notice that we created a copy of the origin rawIn data before filtering.\n",
    "\n",
    "mne.viz.plot_raw(rawInFilt, scalings='auto', remove_dc=False)  # Visualize in Channels X Time format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297a44e-4e1e-4a56-9763-2d729a4619fa",
   "metadata": {},
   "source": [
    "### Rereferencing the data \n",
    "\n",
    "The data needs to be re-referenced. A reference needs to be chosen.\n",
    "The potential measured in microVolts is always measured in relation to the potential at another point, called the reference.\n",
    "\n",
    "This means that the activity at each channel is interpreted relative to the potential at a reference.\n",
    "- the reference can be the mean activity of all electrodes.\n",
    "- the average of the two mastoids (generally these reference channels are marked as Ref1, Ref2 or EXG1, EXG2)\n",
    "The current dataset does not have the external (EXG) channels, so we will apply an average reference.\n",
    "\n",
    "However, we cannot include the bad channels or the VEOG when applying the reference.\n",
    "We use the *pick_types()* method to exclude these channels when applying the average reference.\n",
    "\n",
    "Here we will re-reference in relation to the average of all scalp electrodes, excluding any electrodes that have been\n",
    "marked as being noisy. \n",
    "Other options for the reference are the mastoids (M1, M2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366d214-af1e-4f98-931f-d930ab5c79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInRef = rawInFilt.copy().pick_types(eeg=True, exclude=['bads', 'eog']).set_eeg_reference(ref_channels='average')\n",
    "mne.viz.plot_raw(rawInRef, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc9dab-7696-4084-8b61-35262997a8da",
   "metadata": {},
   "source": [
    "### Finally we will save the highpass filtered and re-referenced data as a *.fif file (MNE-Python format)\n",
    "\n",
    "In MNE-Python, when saving continuous data, the file name has to end _raw.fif.\n",
    "\n",
    "<div class = \"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you are working in Binder, you do not need to do this step. The *.fif file is already available in the data folder.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744cfee-9606-45f7-bfd8-0489864bbd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fnameSave = 'sub-001_eeg_sub-001_task-think1_eeg_short_raw.fif'\n",
    "fullpathSave = os.path.join(filepath, fnameSave)\n",
    "rawInRef.save(fullpathSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38413bcc-9bb7-4475-973f-59d149fa44f6",
   "metadata": {},
   "source": [
    "### Manual annotation of the EEG data\n",
    "\n",
    "We can manually annotate the EEG to mark eye-blinks, electrode-jumps, muscular artifacts.\n",
    "We will open the interactive window. We define 'a' the key to press when we want to annotate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a0814-a65b-4f49-b813-e82ff5c65a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rawIn.plot()\n",
    "fig.fake_keypress('a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
