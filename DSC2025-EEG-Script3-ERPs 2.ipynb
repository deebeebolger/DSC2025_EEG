{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cbcd74a",
   "metadata": {},
   "source": [
    "## Segmenting the continuous data to look at **evoked** activity\n",
    "\n",
    "We have been looking at the continuous data. But in cognitive science, we most often want to study the EEG activity\n",
    "in relation to a stimulus presented during an experiment.\n",
    "We call the activity that is elicited by a stimulus, the **evoked** activity.\n",
    "\n",
    "This type of EEG activity can only be obtained if we apply an experimental protocol in which stimuli are repeatedly\n",
    "presented at regular intervals; these repeated stimulus presentations are referred to as **trials**.\n",
    "To study this evoked activity, we create segments or epochs of data around each stimulus: the time of presentation of the stimulus\n",
    "is referred to as the T0 point and a time interval before and after this T0 is defined.\n",
    "The time interval preceding the T0 (stimulus presentation point) is called the **baseline**.\n",
    "The time interval following the T0 point is called the **post-stimulus interval** and it is in this interval that we study\n",
    "the change in activity that has been evoked by the stimulus.\n",
    "\n",
    "The changes in EEG activity evoked by the stimulus are called the \"event-related potentials\" (ERPs).\n",
    "These are essentially deflections (positive or negative) in activity that can be characterised by:\n",
    "- their latency: when after the stimulus (or event) they appear\n",
    "- their amplitude in micro-volts\n",
    "- their polarity (are they positive or negative going)\n",
    "\n",
    "Thanks to the huge number of ERP studies carried out over the years, researchers have been to attribute certain deflections\n",
    "to certain cognitive phenomenon. For example, semantic processing has been found to be reflected by an erp called the N400...\n",
    "a negative-going ERP that emerges around 400ms after the stimulus. In general, the greater the amplitude of the N400, the more\n",
    "a stimulus is semantically \"unexpected\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48d762-262e-4bf7-9cfb-31cd54f899b5",
   "metadata": {},
   "source": [
    "## Description of the dataset.\n",
    "\n",
    "The following  will use the data from the Three Stimulus Auditory Oddball Task. James F Cavanagh and Davin Quinn (2021). EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI. OpenNeuro. [Dataset] doi: 10.18112/openneuro.ds003522.v1.1.0\n",
    "\n",
    "Reference: Cavanagh JF, Wilson JK, Rieger RE, Gill D, Broadway JM, Story Remer JH, Fratzke V, Mayer AR, Quinn DK. ERPs predict symptomatic distress and recovery in sub-acute mild traumatic brain injury. Neuropsychologia. 2019 Sep;132:107125. doi: 10.1016/j.neuropsychologia.2019.107125. Epub 2019 Jun 19. PMID: 31228481; PMCID: PMC6702033.\n",
    "\n",
    "EEG was recorded from the following three groups of participants while they performed a three-stimulus auditory oddball task:\n",
    "\n",
    "Control participants (group1)\n",
    "Participants with sub-acute mild TBI (Traumatic Brain Injury) (Group0)\n",
    "Participants with chronic TBI (group2)\n",
    "Three sessions of recording were carried out: Session 1: 3 to 14 days following injury Session 2: an average of 2 months post-injury. Session 3: an average of 4 months after session 1.\n",
    "\n",
    "In this task, the participants were presented with three different auditory stimuli:\n",
    "\n",
    "a standard stimulus (presented 80% of the time) - trigger code **1**\n",
    "a novel, non-target stimulus (presented 10% of the time) - trigger code **2**\n",
    "a novel target stimulus (presented 10% of the time) - trigger code **3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46204be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the necessary packages, read in the raw EEG data (in bdf format) and visualize the raw data.\n",
    "## Note when we load in the data using mne.io.read_raw_bdf() this creates a raw object. \n",
    "## In the following code, our raw object is rawIn.\n",
    "%matplotlib widget\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "fname = 'sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.set'\n",
    "filepath = 'data'\n",
    "fullpath = os.path.join(filepath, fname)\n",
    "rawIn = mne.io.read_raw_eeglab(fullpath, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c751bbd-d860-4235-bbe4-64afd8630465",
   "metadata": {},
   "source": [
    "### Let's take a look at the dataset information.\n",
    "- How many channels does the dataset contain?\n",
    "- Does the dataset include any external electrodes?\n",
    "- What sampling frequency was applied when the data was recorded?\n",
    "This information is contained in the **info** object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec607884-2e5a-43fa-bb59-14fe5b1b1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = rawIn.info['ch_names'] \n",
    "chanNumber = len(channels)\n",
    "sfreq = rawIn.info['sfreq']\n",
    "\n",
    "print(f'The number of channels is {chanNumber}.\\n')\n",
    "print(f'The sampling frequency is {sfreq}Hs.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f73b7",
   "metadata": {},
   "source": [
    "### Stop and think!\n",
    "\n",
    "- Has this dataset already been high-pass filtered to take out the DC offset (0Hz component)?\n",
    "- Where might we look to find out?\n",
    "- Can you find out what high-pass filter was applied (the cutoff frequency (hz))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62616e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the imported data...\n",
    "\n",
    "mne.viz.plot_raw(rawIn, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a93ed-db94-4a99-a7a6-3305b8982af2",
   "metadata": {},
   "source": [
    "### What do we need to do to remove the 0Hz (or DC component)?\n",
    "- High pass filter the data. \n",
    "We will *filter out* those frequencies below 0.1Hz, in doing so we remove the 0Hz so that all the EEG signals have a mean of zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2417ad-f89d-46ef-b690-8affedcf8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInFilt = rawIn.copy().filter(0.1, None,\n",
    "                                fir_design='firwin')  # Notice that we created a copy of the origin rawIn data before filtering.\n",
    "\n",
    "mne.viz.plot_raw(rawInFilt, scalings='auto', remove_dc=False)  # Visualize in Channels X Time format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca1ff7-066c-4fde-bd46-6478572b12ea",
   "metadata": {},
   "source": [
    "### We need to re-reference the data.\n",
    "What can we use as the reference with this data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d3d07-58db-4bd1-8b11-6beb12b18142",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInRef = rawInFilt.copy().pick_types(eeg=True, exclude=['bads', 'eog']).set_eeg_reference(ref_channels='average')\n",
    "mne.viz.plot_raw(rawInRef, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770893ed-debe-4ebe-b7f1-545275977903",
   "metadata": {},
   "source": [
    "### Creating events from annotations\n",
    "\n",
    "Extracting the event data from the raw dataset; this information is called \"annotations\"\n",
    " If we look in the annotations attribute of the rawIn object, we will see that we already have information\n",
    " regarding the triggers that mark the time of onset of the stimuli. \n",
    " Here we will create \"events\" based on these annotations using the *.events_from_annotations()* method.\n",
    " We need this event information when we segment the continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, eventid = mne.events_from_annotations(rawInRef)\n",
    "print(events)\n",
    "print(f'The eventid is {eventid}.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6fe18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's carry out segmentation of the continuous\n",
    "# We will define the time limit before (tmin) and after (tmax) the T0, this will decide the length of each epoch.\n",
    "\n",
    "tmin, tmax = [-0.2, 1]  # The time limits defined in seconds.\n",
    "\n",
    "# Call of function to segment the data into epochs.\n",
    "\"\"\"\n",
    "We define the baseline as baseline=(tmin, 0), which means that we will normalise the \n",
    "post-stimulus interval (0 to 1seconds) in relation to the data that is -0.2seconds to 0 \n",
    "before the stimulus. \n",
    "\"\"\"\n",
    "epochData = mne.Epochs(rawInRef, events, event_id=eventid, tmin=tmin, tmax=tmax, reject=None, baseline=(tmin, 0),\n",
    "                       preload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae0601-018f-4460-850b-86397ede780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the segmented (or epoched) data. Each segment defines one epoch that is centered around a stimulus. \n",
    "\n",
    "epochData.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aef37a-b52f-4ce8-b820-f1c9fc3a290e",
   "metadata": {},
   "source": [
    "### We will extract those epochs that correspond to an individual condition.\n",
    "\n",
    "The we can compute the **Event-related Potential (ERP)** by averaging over these epochs. \n",
    "- The epochs referenced by '3' correspond to the **novel tone**.\n",
    "- The epochs referenced by '4' correspond to the **standard tone**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will plot the epochs that correspond to the condition: \n",
    "\"\"\"\n",
    "epochData['3'].plot(events=events, event_id=eventid, butterfly=False)\n",
    "epochData['4'].plot(events=events, event_id=eventid, butterfly=False)\n",
    "cond3 = epochData['3']\n",
    "cond4 = epochData['4']\n",
    "\n",
    "condERP3 = cond3.average()\n",
    "condERP4 = cond4.average()\n",
    "\n",
    "# Now we can plot and compare the evoked activity of both.\n",
    "mne.viz.plot_compare_evokeds(dict(standardTone=condERP3, novelTone=condERP4), legend='upper left', show_sensors=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d301de4-919a-4bd7-8422-f3b875488939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
