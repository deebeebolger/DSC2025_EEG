{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8709fde7",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "\n",
    "For this task you will use the data from the Three Stimulus Auditory Oddball Task.\n",
    "James F Cavanagh and Davin Quinn (2021). EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI.\n",
    "OpenNeuro. [Dataset] doi: 10.18112/openneuro.ds003522.v1.1.0\n",
    "\n",
    "Reference:\n",
    "Cavanagh JF, Wilson JK, Rieger RE, Gill D, Broadway JM, Story Remer JH, Fratzke V, Mayer AR, Quinn DK.\n",
    "ERPs predict symptomatic distress and recovery in sub-acute mild traumatic brain injury. Neuropsychologia. 2019 Sep;132:107125.\n",
    "doi: 10.1016/j.neuropsychologia.2019.107125. Epub 2019 Jun 19. PMID: 31228481; PMCID: PMC6702033.\n",
    "\n",
    "EEG was recorded from the following three groups of participants while they performed a three-stimulus auditory oddball task:\n",
    "- Control participants (group1)\n",
    "- Participants with sub-acute mild TBI (Traumatic Brain Injury) (Group0)\n",
    "- Participants with chronic TBI (group2)\n",
    "\n",
    "Three sessions of recording were carried out:\n",
    "Session 1: 3 to 14 days following injury\n",
    "Session 2: an average of 2 months post-injury.\n",
    "Session 3: an average of 4 months after session 1.\n",
    "\n",
    "In this task, the participants were presented with three different auditory stimuli:\n",
    "- a standard stimulus (presented 80% of the time)\n",
    "- a novel, non-target stimulus (presented 10% of the time)\n",
    "- a novel target stimulus (presented 10% of the time)\n",
    "\n",
    "The datasets related to this study are in the data folder and are entitled:\n",
    "- sub-004-ses-01_task-ThreeStimAuditoryOddball_eeg.edf\n",
    "- sub-004-ses-02_task-ThreeStimAuditoryOddball_eeg.edf\n",
    "\n",
    "In addition, you will need to two text files with the event information:\n",
    "- sub-004-ses-01_task-ThreeStimAuditoryOddball_events.csv\n",
    "- sub-004-ses-02_task-ThreeStimAuditoryOddball_events.csv\n",
    "\n",
    "For this task, you will work from data from sessions 1 and 2 of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad9107",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "\n",
    "Load in the dataset, sub-004_ses-02_task-ThreeStimAuditoryOddball_eeg.edf and carry out the following steps.\n",
    "\n",
    "### Part A\n",
    "\n",
    "1. Print the most important information concerning the EEG data to the screen. Important information means that information\n",
    "which you will need to visualize, process or interpret the data.\n",
    "2. Visualize all channels in such a way that you scroll through and explore the data across time.\n",
    "                    - Note down the times (onset and offset) of any very noisy intervals.\n",
    "                    - Are there only scalp \"eeg\" channels? What other channels are present in the data?\n",
    "4. Remove the DC offset and check that it has been removed.\n",
    "5. Reconstruct the time vector (in seconds) and plot the raw data of a selection of **frontal electrodes**.\n",
    "6. If required, downsample the data. Presuming that we are interested in frequencies up 40Hz, what is the lowest sampling\n",
    "frequency that we can apply?\n",
    "7. Lowpass filter the data, applying a cutoff of 40Hz. Compare the Cz signal before and after filtering.\n",
    "8. Annotate the continuous data, marking the following:\n",
    "    - muscular artifacts\n",
    "    - very large eye blinks\n",
    "9. Note two time intervals presenting these artifacts and display the following figures:\n",
    "    - the time course of the above artifacts; pick channels that best present the artifact.\n",
    "    - the spectrum of these artifacts\n",
    "    - the topography of the artifacts\n",
    "10. Can you identify any particularly noisy electrodes using temporal and spectral visualizations?\n",
    "11. Re-reference the data to the average reference, leaving out any band electrodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f2914",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Try to create a way of automatically detecting eye-blink artifacts.\n",
    "You will need to consider:\n",
    " - the amplitude of the eye-blinks,\n",
    " - how long an eye-blink lasts for and\n",
    " - on which electrodes the eye-blinks typically occur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abecb29d",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Epoch the continuous data that has been at least:\n",
    " - high pass filtered\n",
    " - referenced\n",
    " Take into account the following :\n",
    "    - the baseline needs to 0.2seconds long and before the stimulus.\n",
    "    - the total duration of the epoch needs to 1.2seconds.\n",
    "\n",
    "Three conditions will be defined:\n",
    "- novel tone : 1\n",
    "- standard tone : 2\n",
    "- target tone : 3\n",
    "\n",
    "Plot and the compare the ERPs (evoked data) of the three types of tones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e877b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to import the necessary packages.\n",
    "import mne\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Load in the rawdata (*.edf dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeedb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code to help with the segmentation.\n",
    "# You will segment the rawdata that has been highpass filterd and re-referenced at least,\n",
    "# rawdataRef.\n",
    "fpath = 'data'\n",
    "fname_event = 'sub-004_ses-02_task-ThreeStimAuditoryOddball_events.csv'\n",
    "fullpath  = os.path.join(fpath, fname_event)\n",
    "event_data = pd.read_csv(fullpath, sep=';', header=None)\n",
    "annotations = mne.Annotations(event_data[0], event_data[1], event_data[2])\n",
    "\n",
    "rawdataRef.set_annotations(annotations)\n",
    "events, event_id = mne.events_from_annotations(rawdataRef)\n",
    "\n",
    "# We define two conditions as a dictionary.\n",
    "event_dict = {'Novel Tone': 1, 'Standard Tone': 2, 'Target Tone': 3}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
