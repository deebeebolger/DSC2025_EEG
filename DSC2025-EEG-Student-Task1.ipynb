{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33e13df",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "\n",
    "For this task you will use the data from the Three Stimulus Auditory Oddball Task.\n",
    "James F Cavanagh and Davin Quinn (2021). EEG: Three-Stim Auditory Oddball and Rest in Acute and Chronic TBI.\n",
    "OpenNeuro. [Dataset] doi: 10.18112/openneuro.ds003522.v1.1.0\n",
    "\n",
    "Reference:\n",
    "Cavanagh JF, Wilson JK, Rieger RE, Gill D, Broadway JM, Story Remer JH, Fratzke V, Mayer AR, Quinn DK.\n",
    "ERPs predict symptomatic distress and recovery in sub-acute mild traumatic brain injury. Neuropsychologia. 2019 Sep;132:107125.\n",
    "doi: 10.1016/j.neuropsychologia.2019.107125. Epub 2019 Jun 19. PMID: 31228481; PMCID: PMC6702033.\n",
    "\n",
    "EEG was recorded from the following three groups of participants while they performed a three-stimulus auditory oddball task:\n",
    "- Control participants (group1)\n",
    "- Participants with sub-acute mild TBI (Traumatic Brain Injury) (Group0)\n",
    "- Participants with chronic TBI (group2)\n",
    "\n",
    "Three sessions of recording were carried out:\n",
    "Session 1: 3 to 14 days following injury\n",
    "Session 2: an average of 2 months post-injury.\n",
    "Session 3: an average of 4 months after session 1.\n",
    "\n",
    "In this task, the participants were presented with three different auditory stimuli:\n",
    "- a standard stimulus (presented 80% of the time)\n",
    "- a novel, non-target stimulus (presented 10% of the time)\n",
    "- a novel target stimulus (presented 10% of the time)\n",
    "\n",
    "The datasets related to this study are in the data folder and are entitled:\n",
    "- **sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.set** and corresponding associated **sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.fdt** file\n",
    "- **sub-004_ses-02_task-ThreeStimAuditoryOddball_eeg_segment1.set** and its corresponding **sub-004_ses-02_task-ThreeStimAuditoryOddball_eeg_segment1.fdt file**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<Important!</b>\n",
    "For this task, you will work from data from sessions 1 of the study. So you will need to load in the files: sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.set.\n",
    "If you are working in Binder, you will need to upload these two files to the data folder :\n",
    "\n",
    "- sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.set\n",
    "- sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.fdt.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6143d",
   "metadata": {},
   "source": [
    "## Task 1 instructions\n",
    "\n",
    "Using the script **DSC-EEG-Script1.ipynb** as a guide to carry out the following:\n",
    "\n",
    "- To get you started, the code is provided for loading in and visualizing the raw data. \n",
    "- Extract the following dataset information:\n",
    "    - the sampling frequency (Hz)\n",
    "    - the names and the type of the channels\n",
    "    - the number of sample points\n",
    "    - the time vector \n",
    "- Determine and display the temporal resolution of the dataset. Hint: use the sampling frequency.  \n",
    "- Do you need to remove the DC component? Do this if needed.\n",
    "- What reference will you apply to the data? Plot the referenced data. \n",
    "- Can you spot any artifacts in the data? Can you identify the artifact?\n",
    "- Present a **temporal** and **spatial** visualization of the artifact. For the temporal visualization you can plot one or several individual electrodes. \n",
    "\n",
    "- Load in the dataset corresponding to the second session, **Session 2** and carry out the same visualisation and processing steps as for the first baseline run. Then compare the two datasets.\n",
    "\n",
    "Do you notice any differences between the two? \n",
    "If so, present figures that highlight these differences. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<Note!</b>\n",
    "I have added the code at the end that allows you to calculate the average activity over a time interval and plot the spatial distribution of this activity as a topography or topographic map. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code in cells here. Maybe a cell per answer...\n",
    "# Don't forget to import the required packages.\n",
    "# The matplotlib widget line faciltates the presentation of interactive plots.\n",
    "\n",
    "%matplotlib widget\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Help for loading in the *.set file:\n",
    "filename = 'sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg_segment1.set' # This .set file will automatically look for its corresponding *.fdt file\n",
    "filepath = 'Data'\n",
    "fullpath = os.path.join(filepath, filename)\n",
    "rawIn = mne.io.read_raw_eeglab(fullpath, preload=True)\n",
    "rawIn.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db99a8b1-d6bf-4a60-9567-28f8cf0375f7",
   "metadata": {},
   "source": [
    "### Assign channel types to the raw object\n",
    "This will allow us to distinguish between scalp electrodes and external electrodes positioned on the face to record\n",
    "eye movements. \n",
    "**VEOG** means *Vertical Electro-oculograms*, otherwise called **eye-blinks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawIn.info['ch_names']\n",
    "\n",
    "my_dict = {'VEOG': 'eog'}\n",
    "print(my_dict)\n",
    "rawIn.set_channel_types(my_dict)  # Apply the channel type to our raw object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9999a50-e5fe-4d57-b5bd-956b95df6f5d",
   "metadata": {},
   "source": [
    "### Preparing the raw object so that we can plot the topography.\n",
    "\n",
    "In addition to looking at the signal as a function, we can look at the spatial distribution \n",
    "of activity across the head (topography) over a given time interval.\n",
    "A topography over a time interval can be used to highlight activity at a specific time interval. \n",
    "To plot a single topography, we need to define a vector of the mean activity over define time interval for each\n",
    "electrode.\n",
    "\n",
    "Before we can visualize the topography, we need to define the electrode layout or **montage** that corresponds to \n",
    "the current dataset's configuration. \n",
    "\n",
    "Here the **montage** is the standard **10-20 configuration** which defines how the electrodes are positioned relative to one another on the scalp. The inter-electrode distance is either 10% or 20% of the total length and width of the head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10ef44-a01a-419c-9e72-bd393c8b1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign the standard 10-20 montage to the raw object. \n",
    "\n",
    "montage = mne.channels.make_standard_montage('standard_1020')  # Assigning the standard 10-20 montage\n",
    "mne.viz.plot_montage(mne.channels.make_standard_montage('standard_1020'))  # Visualize the montage\n",
    "rawIn.set_montage(montage)                                                 # Assign the 10-20 montage to the raw object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e116c-5afe-4506-af8a-738e64e759f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeIntval = [10, 15]                       # Defining the time interval (10-15 seconds) over which to plot the topography.\n",
    "timeIndx = rawIn.time_as_index(timeIntval)  # Express the times in seconds as indices using the time_as_index() method.\n",
    "chanRange = np.arange(0, 64)                # We will plot only the first 63 electrodes, the scalp electrodes.\n",
    "\n",
    "# Extract the data from the raw object as an array with dimensions Channel number X Time points\n",
    "dataIn = np.array(rawIn.get_data())\n",
    "dataSeg1 = dataIn[chanRange, timeIndx[0]:timeIndx[1]]\n",
    "dataSeg_mean = np.mean(dataSeg1, 1)\n",
    "\n",
    "# Visualise the average activity over the time interval as a topography. \n",
    "fig1, ax1 = plt.subplots(1)\n",
    "mne.viz.plot_topomap(dataSeg_mean, rawIn.info, ch_type='eeg', axes=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890f3a2-1605-4af4-82b7-d211746c0df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
